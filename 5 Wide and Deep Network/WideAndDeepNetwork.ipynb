{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment Five: Wide and Deep Network\n",
    "\n",
    "### Luis Garduno\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - Brief Business Understanding\n",
    "\n",
    "#### <ins>`About League of Legends`<ins>\n",
    "\n",
    "Developed by Riot Studios, League of Legends, or \"LoL\", is an online multiplayer\n",
    "video-game that is available to Windows/MacOS users. LoL consists 2 teams ('Blue\n",
    "&amp; 'Red') facing each other, where the main objective is to destroy the opposing\n",
    "teams 'Nexus', or home base, while facing obstacles like destroying damage dealing\n",
    "towers &amp; eliminating players throughout the way. Perks &amp; gold are able to be\n",
    "obtained by players/teams through completing tasks such as eliminating players,\n",
    "enemy creeps, or dragons. Players then spend the gold to purchase items that help\n",
    "raise the power of their abilities.\n",
    "\n",
    "League of Legends offers different game modes, such as ranked. In this game mode,\n",
    "players are given a rank based off of the number of wins + the number of games\n",
    "played. \"Diamond\" is one of the highest ranks a player may obtain and is known\n",
    "to be extremely competitive. A ranked game on average lasts 30-45 minutes. The\n",
    "dataset we will be using contains the first 10 minute analytics of each team\n",
    "for different diamond ranked matches.\n",
    "\n",
    "#### <ins>`Measure of Success`<ins>\n",
    "\n",
    "Once the data is analyzed, third parties, or teams/players, would be able to conceptualize the level\n",
    "of priority different attributes have during early stages of diamond ranked matches. With the first\n",
    "ten minutes of each game being critical, they could then use this information to adjust their strategy\n",
    "to one proven to win matches. In order for this data to be useful and trusted by third parties in\n",
    "specific situations such as playing at professional level, the data would have to render at least a 80%\n",
    "accuracy. The reason for it being 80% and not any higher is because as mentioned this data only include\n",
    "the first 10 minutes of a game (average full game: 30-45 minutes). We leave a 20% error gap for any\n",
    "changes of pace the winning team might have for the remaining time of the game (~67%).\n",
    "\n",
    "Additionally, players who are accustomed to playing as the 'jungle' role (a player\n",
    "role that focuses on obtaining objective eliminations within the jungle areas of\n",
    "the map) can use this analyzed data to better understand the impact elite monsters\n",
    "have on winning games.\n",
    "\n",
    "-------------------------------------\n",
    "\n",
    "Dataset [Kaggle]: <a href=\"https://www.kaggle.com/bobbyscience/league-of-legends-diamond-ranked-games-10-min\" target=\"_top\"><b>First 10 minutes of diamond ranked League of Legends matches</b></a>\n",
    "\n",
    "Question Of Interest : As of the first 10 minutes, which team will win?\n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Loading Data & Adjustments (10%)\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9879 entries, 0 to 9878\n",
      "Data columns (total 40 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   gameId                        9879 non-null   int64  \n",
      " 1   blueWins                      9879 non-null   int64  \n",
      " 2   blueWardsPlaced               9879 non-null   int64  \n",
      " 3   blueWardsDestroyed            9879 non-null   int64  \n",
      " 4   blueFirstBlood                9879 non-null   int64  \n",
      " 5   blueKills                     9879 non-null   int64  \n",
      " 6   blueDeaths                    9879 non-null   int64  \n",
      " 7   blueAssists                   9879 non-null   int64  \n",
      " 8   blueEliteMonsters             9879 non-null   int64  \n",
      " 9   blueDragons                   9879 non-null   int64  \n",
      " 10  blueHeralds                   9879 non-null   int64  \n",
      " 11  blueTowersDestroyed           9879 non-null   int64  \n",
      " 12  blueTotalGold                 9879 non-null   int64  \n",
      " 13  blueAvgLevel                  9879 non-null   float64\n",
      " 14  blueTotalExperience           9879 non-null   int64  \n",
      " 15  blueTotalMinionsKilled        9879 non-null   int64  \n",
      " 16  blueTotalJungleMinionsKilled  9879 non-null   int64  \n",
      " 17  blueGoldDiff                  9879 non-null   int64  \n",
      " 18  blueExperienceDiff            9879 non-null   int64  \n",
      " 19  blueCSPerMin                  9879 non-null   float64\n",
      " 20  blueGoldPerMin                9879 non-null   float64\n",
      " 21  redWardsPlaced                9879 non-null   int64  \n",
      " 22  redWardsDestroyed             9879 non-null   int64  \n",
      " 23  redFirstBlood                 9879 non-null   int64  \n",
      " 24  redKills                      9879 non-null   int64  \n",
      " 25  redDeaths                     9879 non-null   int64  \n",
      " 26  redAssists                    9879 non-null   int64  \n",
      " 27  redEliteMonsters              9879 non-null   int64  \n",
      " 28  redDragons                    9879 non-null   int64  \n",
      " 29  redHeralds                    9879 non-null   int64  \n",
      " 30  redTowersDestroyed            9879 non-null   int64  \n",
      " 31  redTotalGold                  9879 non-null   int64  \n",
      " 32  redAvgLevel                   9879 non-null   float64\n",
      " 33  redTotalExperience            9879 non-null   int64  \n",
      " 34  redTotalMinionsKilled         9879 non-null   int64  \n",
      " 35  redTotalJungleMinionsKilled   9879 non-null   int64  \n",
      " 36  redGoldDiff                   9879 non-null   int64  \n",
      " 37  redExperienceDiff             9879 non-null   int64  \n",
      " 38  redCSPerMin                   9879 non-null   float64\n",
      " 39  redGoldPerMin                 9879 non-null   float64\n",
      "dtypes: float64(6), int64(34)\n",
      "memory usage: 3.0 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load in the dataset into dataframe\n",
    "dataset = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/Datasets/high_diamond_ranked_10min.csv')\n",
    "\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------------------------------\n",
    "\n",
    "Printing out the information about the dataframe we are able to see that there are a\n",
    "total of 9,879 instances, and 39 attributes.\n",
    "\n",
    "Additionally we are able to see that there are 19 of the same attributes for each\n",
    "the blue & red team (columns 1-19 are the same as 20-38).\n",
    "\n",
    "Attributes for each team includes :\n",
    "- Wards placed & destroyed\n",
    "- Total number of kills, deaths, & assists\n",
    "- First Bloods (1st elimination of the game)\n",
    "- Total : towers destroyed, gold, experience\n",
    "- Average : level, CS per minute, & gold per minute\n",
    "- Difference in gold & experience between the teams\n",
    "- Objective eliminations : elite monsters(dragons, heralds), minions, & jungle minions\n",
    "\n",
    "Attributes such as total gold, experience, objectives eliminations, towers destroyed, etc.\n",
    "will be of type integer (int64) because they will always be whole numbers. Attributes involving\n",
    "averages such as cs per minute, gold per minute, & level, should be the only of double-precision floating-point\n",
    "format (float64).\n",
    "\n",
    "The data type for \"blueWins\" and \"first bloods\" could be changed to be of type boolean, but because we are wanting to\n",
    "visualize these attributes later on, optimally it is best to keep these as integer data types. As a result,\n",
    "the data types presented for each attribute are correct and should not be changed.\n",
    "\n",
    "Below is a brief description of some of the key attributes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "             gameId     blueWins  blueWardsPlaced  blueWardsDestroyed  \\\ncount  9.879000e+03  9879.000000      9879.000000         9879.000000   \nmean   4.500084e+09     0.499038        22.288288            2.824881   \nstd    2.757328e+07     0.500024        18.019177            2.174998   \nmin    4.295358e+09     0.000000         5.000000            0.000000   \n25%    4.483301e+09     0.000000        14.000000            1.000000   \n50%    4.510920e+09     0.000000        16.000000            3.000000   \n75%    4.521733e+09     1.000000        20.000000            4.000000   \nmax    4.527991e+09     1.000000       250.000000           27.000000   \n\n       blueFirstBlood    blueKills   blueDeaths  blueAssists  \\\ncount     9879.000000  9879.000000  9879.000000  9879.000000   \nmean         0.504808     6.183925     6.137666     6.645106   \nstd          0.500002     3.011028     2.933818     4.064520   \nmin          0.000000     0.000000     0.000000     0.000000   \n25%          0.000000     4.000000     4.000000     4.000000   \n50%          1.000000     6.000000     6.000000     6.000000   \n75%          1.000000     8.000000     8.000000     9.000000   \nmax          1.000000    22.000000    22.000000    29.000000   \n\n       blueEliteMonsters  blueDragons  ...  redTowersDestroyed  redTotalGold  \\\ncount        9879.000000  9879.000000  ...         9879.000000   9879.000000   \nmean            0.549954     0.361980  ...            0.043021  16489.041401   \nstd             0.625527     0.480597  ...            0.216900   1490.888406   \nmin             0.000000     0.000000  ...            0.000000  11212.000000   \n25%             0.000000     0.000000  ...            0.000000  15427.500000   \n50%             0.000000     0.000000  ...            0.000000  16378.000000   \n75%             1.000000     1.000000  ...            0.000000  17418.500000   \nmax             2.000000     1.000000  ...            2.000000  22732.000000   \n\n       redAvgLevel  redTotalExperience  redTotalMinionsKilled  \\\ncount  9879.000000         9879.000000            9879.000000   \nmean      6.925316        17961.730438             217.349226   \nstd       0.305311         1198.583912              21.911668   \nmin       4.800000        10465.000000             107.000000   \n25%       6.800000        17209.500000             203.000000   \n50%       7.000000        17974.000000             218.000000   \n75%       7.200000        18764.500000             233.000000   \nmax       8.200000        22269.000000             289.000000   \n\n       redTotalJungleMinionsKilled   redGoldDiff  redExperienceDiff  \\\ncount                  9879.000000   9879.000000        9879.000000   \nmean                     51.313088    -14.414111          33.620306   \nstd                      10.027885   2453.349179        1920.370438   \nmin                       4.000000 -11467.000000       -8348.000000   \n25%                      44.000000  -1596.000000       -1212.000000   \n50%                      51.000000    -14.000000          28.000000   \n75%                      57.000000   1585.500000        1290.500000   \nmax                      92.000000  10830.000000        9333.000000   \n\n       redCSPerMin  redGoldPerMin  \ncount  9879.000000    9879.000000  \nmean     21.734923    1648.904140  \nstd       2.191167     149.088841  \nmin      10.700000    1121.200000  \n25%      20.300000    1542.750000  \n50%      21.800000    1637.800000  \n75%      23.300000    1741.850000  \nmax      28.900000    2273.200000  \n\n[8 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gameId</th>\n      <th>blueWins</th>\n      <th>blueWardsPlaced</th>\n      <th>blueWardsDestroyed</th>\n      <th>blueFirstBlood</th>\n      <th>blueKills</th>\n      <th>blueDeaths</th>\n      <th>blueAssists</th>\n      <th>blueEliteMonsters</th>\n      <th>blueDragons</th>\n      <th>...</th>\n      <th>redTowersDestroyed</th>\n      <th>redTotalGold</th>\n      <th>redAvgLevel</th>\n      <th>redTotalExperience</th>\n      <th>redTotalMinionsKilled</th>\n      <th>redTotalJungleMinionsKilled</th>\n      <th>redGoldDiff</th>\n      <th>redExperienceDiff</th>\n      <th>redCSPerMin</th>\n      <th>redGoldPerMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9.879000e+03</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>...</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n      <td>9879.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>4.500084e+09</td>\n      <td>0.499038</td>\n      <td>22.288288</td>\n      <td>2.824881</td>\n      <td>0.504808</td>\n      <td>6.183925</td>\n      <td>6.137666</td>\n      <td>6.645106</td>\n      <td>0.549954</td>\n      <td>0.361980</td>\n      <td>...</td>\n      <td>0.043021</td>\n      <td>16489.041401</td>\n      <td>6.925316</td>\n      <td>17961.730438</td>\n      <td>217.349226</td>\n      <td>51.313088</td>\n      <td>-14.414111</td>\n      <td>33.620306</td>\n      <td>21.734923</td>\n      <td>1648.904140</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.757328e+07</td>\n      <td>0.500024</td>\n      <td>18.019177</td>\n      <td>2.174998</td>\n      <td>0.500002</td>\n      <td>3.011028</td>\n      <td>2.933818</td>\n      <td>4.064520</td>\n      <td>0.625527</td>\n      <td>0.480597</td>\n      <td>...</td>\n      <td>0.216900</td>\n      <td>1490.888406</td>\n      <td>0.305311</td>\n      <td>1198.583912</td>\n      <td>21.911668</td>\n      <td>10.027885</td>\n      <td>2453.349179</td>\n      <td>1920.370438</td>\n      <td>2.191167</td>\n      <td>149.088841</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>4.295358e+09</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>11212.000000</td>\n      <td>4.800000</td>\n      <td>10465.000000</td>\n      <td>107.000000</td>\n      <td>4.000000</td>\n      <td>-11467.000000</td>\n      <td>-8348.000000</td>\n      <td>10.700000</td>\n      <td>1121.200000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.483301e+09</td>\n      <td>0.000000</td>\n      <td>14.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>15427.500000</td>\n      <td>6.800000</td>\n      <td>17209.500000</td>\n      <td>203.000000</td>\n      <td>44.000000</td>\n      <td>-1596.000000</td>\n      <td>-1212.000000</td>\n      <td>20.300000</td>\n      <td>1542.750000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.510920e+09</td>\n      <td>0.000000</td>\n      <td>16.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>6.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>16378.000000</td>\n      <td>7.000000</td>\n      <td>17974.000000</td>\n      <td>218.000000</td>\n      <td>51.000000</td>\n      <td>-14.000000</td>\n      <td>28.000000</td>\n      <td>21.800000</td>\n      <td>1637.800000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4.521733e+09</td>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>8.000000</td>\n      <td>8.000000</td>\n      <td>9.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>17418.500000</td>\n      <td>7.200000</td>\n      <td>18764.500000</td>\n      <td>233.000000</td>\n      <td>57.000000</td>\n      <td>1585.500000</td>\n      <td>1290.500000</td>\n      <td>23.300000</td>\n      <td>1741.850000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>4.527991e+09</td>\n      <td>1.000000</td>\n      <td>250.000000</td>\n      <td>27.000000</td>\n      <td>1.000000</td>\n      <td>22.000000</td>\n      <td>22.000000</td>\n      <td>29.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>22732.000000</td>\n      <td>8.200000</td>\n      <td>22269.000000</td>\n      <td>289.000000</td>\n      <td>92.000000</td>\n      <td>10830.000000</td>\n      <td>9333.000000</td>\n      <td>28.900000</td>\n      <td>2273.200000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# describe dataframe\n",
    "dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                       Features  \\\n0                      blueWins   \n1  WardsPlaced / WardsDestroyed   \n2                    FirstBlood   \n3      Kills / Deaths / Assists   \n4               TowersDestroyed   \n5                     TotalGold   \n6                      AvgLevel   \n7               TotalExperience   \n8                      CSPerMin   \n9                    GoldPerMin   \n\n                                         Description Feature type  \\\n0                       whether blue team won or not     Discrete   \n1  number of total wards placed or destroyed by team   Continuous   \n2                   team with the first kill of game     Discrete   \n3  total number of kills, deaths, or assists of team   Continuous   \n4           total number of towers destroyed by team   Continuous   \n5                        total gold obtained by team   Continuous   \n6               average level of all players on team   Continuous   \n7        total experience points accumulated by team   Continuous   \n8                     average creep score per minute   Continuous   \n9                   average gold obtained per minute   Continuous   \n\n  Attribute Type                                              Range  \n0        nominal                  0: red team won; 1: blue team won  \n1          ratio                  placed: 5 - 250;destroyed: 0 - 27  \n2        nominal  0: did not get first kill; 1: team obtained fi...  \n3          ratio             kills: 0-22;deaths: 0-22;assists: 0-29  \n4          ratio                                              0 - 2  \n5          ratio                                    11,000 - 25,000  \n6          ratio                                          4.5 - 8.5  \n7          ratio                                    10,000 - 24,000  \n8          ratio                                        10.0 - 30.0  \n9          ratio                                  1,100.0 - 2,000.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Features</th>\n      <th>Description</th>\n      <th>Feature type</th>\n      <th>Attribute Type</th>\n      <th>Range</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>blueWins</td>\n      <td>whether blue team won or not</td>\n      <td>Discrete</td>\n      <td>nominal</td>\n      <td>0: red team won; 1: blue team won</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>WardsPlaced / WardsDestroyed</td>\n      <td>number of total wards placed or destroyed by team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>placed: 5 - 250;destroyed: 0 - 27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>FirstBlood</td>\n      <td>team with the first kill of game</td>\n      <td>Discrete</td>\n      <td>nominal</td>\n      <td>0: did not get first kill; 1: team obtained fi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Kills / Deaths / Assists</td>\n      <td>total number of kills, deaths, or assists of team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>kills: 0-22;deaths: 0-22;assists: 0-29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TowersDestroyed</td>\n      <td>total number of towers destroyed by team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>0 - 2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>TotalGold</td>\n      <td>total gold obtained by team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>11,000 - 25,000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AvgLevel</td>\n      <td>average level of all players on team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>4.5 - 8.5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>TotalExperience</td>\n      <td>total experience points accumulated by team</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>10,000 - 24,000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>CSPerMin</td>\n      <td>average creep score per minute</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>10.0 - 30.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GoldPerMin</td>\n      <td>average gold obtained per minute</td>\n      <td>Continuous</td>\n      <td>ratio</td>\n      <td>1,100.0 - 2,000.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_describe = pd.DataFrame({'Features' : ['blueWins','WardsPlaced / WardsDestroyed','FirstBlood','Kills / Deaths / Assists',\n",
    "                                         'TowersDestroyed','TotalGold','AvgLevel','TotalExperience','CSPerMin','GoldPerMin']})\n",
    "\n",
    "dataset_describe['Description'] = ['whether blue team won or not','number of total wards placed or destroyed by team','team with the first kill of game',\n",
    "                             'total number of kills, deaths, or assists of team','total number of towers destroyed by team','total gold obtained by team',\n",
    "                             'average level of all players on team','total experience points accumulated by team','average creep score per minute','average gold obtained per minute']\n",
    "\n",
    "dataset_describe['Feature type'] = ['Discrete','Continuous','Discrete','Continuous','Continuous','Continuous','Continuous','Continuous','Continuous','Continuous']\n",
    "\n",
    "dataset_describe['Attribute Type'] = ['nominal','ratio','nominal','ratio','ratio','ratio','ratio','ratio','ratio','ratio']\n",
    "\n",
    "dataset_describe['Range'] = ['0: red team won; 1: blue team won','placed: 5 - 250;destroyed: 0 - 27','0: did not get first kill; 1: team obtained first kill',\n",
    "                       'kills: 0-22;deaths: 0-22;assists: 0-29','0 - 2','11,000 - 25,000','4.5 - 8.5','10,000 - 24,000','10.0 - 30.0','1,100.0 - 2,000.0']\n",
    "dataset_describe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1.2 Normalizing the Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on RangeIndex with these indexers [0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n9874    1\n9875    1\n9876    0\n9877    0\n9878    1\nName: blueWins, Length: 9879, dtype: int64] of type Series",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-51-145ad50365fc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m \u001B[0mcol_names\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'blueWins'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[0mdataset_normalized\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;34m'blueWins'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_normalized\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcol_names\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\check\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2879\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2880\u001B[0m         \u001B[1;31m# Do we have a slicer (on rows)?\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2881\u001B[1;33m         \u001B[0mindexer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_to_index_sliceable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2882\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindexer\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2883\u001B[0m             \u001B[1;31m# either we have a slice or we have a string that can be converted\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\check\\lib\\site-packages\\pandas\\core\\indexing.py\u001B[0m in \u001B[0;36mconvert_to_index_sliceable\u001B[1;34m(obj, key)\u001B[0m\n\u001B[0;32m   2132\u001B[0m     \u001B[0midx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mindex\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2133\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mslice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2134\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_convert_slice_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"getitem\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2135\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2136\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\check\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36m_convert_slice_indexer\u001B[1;34m(self, key, kind)\u001B[0m\n\u001B[0;32m   3155\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mis_index_slice\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3156\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"slice\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstart\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"getitem\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3157\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"slice\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstop\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"getitem\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3158\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"slice\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"getitem\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3159\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\check\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36m_validate_indexer\u001B[1;34m(self, form, key, kind)\u001B[0m\n\u001B[0;32m   4995\u001B[0m             \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4996\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 4997\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_invalid_indexer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mform\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   4998\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   4999\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_maybe_cast_slice_bound\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mside\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr_t\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\check\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001B[0m in \u001B[0;36m_invalid_indexer\u001B[1;34m(self, form, key)\u001B[0m\n\u001B[0;32m   3266\u001B[0m         \"\"\"\n\u001B[0;32m   3267\u001B[0m         raise TypeError(\n\u001B[1;32m-> 3268\u001B[1;33m             \u001B[1;34mf\"cannot do {form} indexing on {type(self).__name__} with these \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3269\u001B[0m             \u001B[1;34mf\"indexers [{key}] of type {type(key).__name__}\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3270\u001B[0m         )\n",
      "\u001B[1;31mTypeError\u001B[0m: cannot do slice indexing on RangeIndex with these indexers [0       0\n1       0\n2       0\n3       0\n4       0\n       ..\n9874    1\n9875    1\n9876    0\n9877    0\n9878    1\nName: blueWins, Length: 9879, dtype: int64] of type Series"
     ]
    }
   ],
   "source": [
    "# We need to use proper variable representations (int, float, one-hot, etc.).\n",
    "# Before we begin making adjustments to the dataframe, we should normalize the given values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "col_names = dataset.columns\n",
    "dataset_normalized = preprocessing.normalize(dataset)\n",
    "df = pd.DataFrame(dataset_normalized, columns=col_names)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "---------------\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1.3 Data Quality\n",
    "\n",
    "Using the `missingno` package, we are able to additionally confirm that all the data is complete\n",
    "and there is no missing entries with the dataset. If there was missing data, we could impute the\n",
    "missing values by using the k-nearest neighbor. But if an instance was missing a majority of its\n",
    "attributes, it would be removed from the dataset.\n",
    "\n",
    "The number of unique values in the column \"gameId\" is printed to verify that all instances\n",
    "are weighted equally."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df)\n",
    "\n",
    "# Count unique values in column 'gameId' of the dataframe\n",
    "print('Number of unique values in column \"gameId\" : ', df['gameId'].nunique())\n",
    "\n",
    "dup_df = df.replace(to_replace=-1,value=np.nan)\n",
    "\n",
    "dup_df = dup_df.duplicated()\n",
    "print('Duplicates : ', len(df[dup_df]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "------------------------------\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1.4 Cleaning the Dataset\n",
    "\n",
    "After confirming there are no duplicates in the data, the \"gameId\" column can be removed since it\n",
    "will have no impact on the results.\n",
    "\n",
    "Using the correlation feature from the `pandas` package, for each team we find the names of\n",
    "attributes that correlate most with winning (correlation >= 7%). The names of these attributes\n",
    "are stored in a array for later use.\n",
    "\n",
    "Lastly, two dataframes are created to hold the attributes at instances when blue team wins, and\n",
    "when blue team loses."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del df['gameId']\n",
    "\n",
    "red_col = df.corr()[df.corr()['blueWins'] <= -0.07].index.values\n",
    "blue_col = df.corr()[df.corr()['blueWins'] >= 0.07].index.values\n",
    "\n",
    "# Create dataframes for the 2 possible outcomes :\n",
    "df_win  = df[df[\"blueWins\"]==1.0]     # Blue Team Win  /  Red Team Lost\n",
    "df_lose = df[df[\"blueWins\"]==0.0]     # Red Team Win   /  Blue Team Lost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Finding & Creating Cross-Product Features (20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Identify groups of features in my data that should be combined into cross-product features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Provide justification for why these features should be crossed (or why some features shouldn't be crossed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Measuring Algorithm Performance (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"blueWins\", data=df, palette=['red', 'blue'])\n",
    "ax.set_title('Win Rate by Team')\n",
    "ax.set_xlabel('Teams')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['Red', 'Blue'])\n",
    "ax.set_ylabel('Frequency')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Choose & explain what metric(s) I will use to evaluate your algorithm’s performance.\n",
    "- I should give a detailed argument for why this (these) metric(s) are appropriate on my data.\n",
    "- That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task).\n",
    "- Note: rarely is accuracy the best evaluation metric to use.Think deeply about an appropriate measure of performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "-------------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.4 Splitting the Dataset (40%)\n",
    "Using Scikit-learn's\n",
    "<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html\" target=\"_top\"><b>cross-validation modules</b></a>\n",
    "we are able to split our dataset for training and testing purposes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X data & y target dataframe's\n",
    "if 'blueWins' in df:\n",
    "    y = df['blueWins'].values\n",
    "    del df['blueWins']\n",
    "    X = df.to_numpy()\n",
    "\n",
    "\n",
    "# Divide the data: 80% Training & 20% Testing.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, test_size=0.1, random_state=0)\n",
    "\n",
    "print(\"Training Set\", \"\\n   - Data Shape:\",X_train.shape,\"\\n   - Target Shape:\",y_train.shape)\n",
    "print(\"\\nTesting Set\",\"\\n   - Data Shape:\",X_test.shape ,\"\\n   - Target Shape:\",y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------------------\n",
    "\n",
    "We perform a split within our dataset: 90% will be used for training, and 10% for testing. The 80/20 split is appropriate for\n",
    "the dataset because recall that the end goal is for users to be able to determine the probabilities of them winning their\n",
    "on-going game, or in other words we will only be predicting the win probability of __ONE__ game.\n",
    "\n",
    "Additionally if a 95/5 split was applied it would also be appropriate to use as well. With League of Legends being a\n",
    "strategy based game, our prediction algorithm essentially uses the training data to find which combination of\n",
    "objectives/attributes have the biggest impact/correlation withing winning games. These game winning objectives/attributes could\n",
    "be found quite early on during training, but we need to account that these objectives/attributes can be wrong in certain\n",
    "instances due to the fact of the dataset only containing attributes for the first 10 minutes. So as the size of the training\n",
    "set increases, the amount of fine-tunning performed increases, thus rendering a higher accuracy when predicting through the\n",
    "testing dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Choose the method I will use for dividing my data into training & testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Explain what i'm using & why (i.e Stratified 10-fold cross validation? Shuffle splits?)\n",
    "- Explain why my chosen method is appropriate or use more than one method as appropriate.\n",
    "- Argue why my cross validation method is a realistic mirroring of how an algorithm would be used in practice. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------------\n",
    "\n",
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Creating Wide & Deep Networks (60%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Create at least 3 combined wide & deep networks to classify your data using Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Visualize the performance of the network on the training data & validation data in:\n",
    "# - the same plot\n",
    "# - vs.\n",
    "# - training iterations.\n",
    "# - Note: use the \"history\" return parameter that is part of Keras \"fit\" function to easily access this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Investigating Generalization Performance (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Investigate generalization performance by altering the number of layers in the deep branch of the network.\n",
    "# - Try at least 2 different number of layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Use the method of cross validation & evaluation metric I chose at the start of the lab to help select\n",
    "#   the # of layers that performs superiorly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Comparing Performaces (90%)\n",
    "\n",
    "- Use proper statistical method to compare the performance of different models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - Compare the performance of my best wide & deep network to a standard multi-layer perceptron (MLP).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# - For classification tasks, use the receiver operating characteristic & area under the curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#- For regression tasks, use Bland-Altman plots & residual variance calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "## 3. t-SNE Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}