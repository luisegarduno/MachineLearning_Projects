{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Six: CNN's\n",
    "\n",
    "### Luis Garduno\n",
    "## Brief Business Understanding\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>`About STL-10`</u>\n",
    "\n",
    "Inspired by the\n",
    "<a href=\"http://www.cs.toronto.edu/~kriz/cifar.html\" target=\"_top\"><b>CIFAR-10</b></a>\n",
    "dataset, STL-10 is a dataset containing a combination of images (gathered from\n",
    "<a href=\"http://www.image-net.org/\" target=\"_top\"><b>ImageNet</b></a>)\n",
    "of animals and transportation objects. Within the dataset there are 6 animal & 4 transportation object classes:\n",
    "- __Animals__ : bird, cat, deer, dog, horse, monkey\n",
    "- __Transportation Objects__ : airplane, car, ship, truck\n",
    "\n",
    "The dataset contains 3 folders that will be used at specified times:\n",
    "- __Train__ : 5000 images used to train the algorithm\n",
    "- __Test__ : 8000 images used to test an algorithm (800 images per class)\n",
    "- __Unlabeled__ : 100,000 unlabeled image files\n",
    "\n",
    "Aside from having not having identical classes, another difference between the datasets, is that the\n",
    "images in STL-10 are 3x's the resolution of CIFAR-10's images (96x96 versus 32x32).\n",
    "\n",
    "STL-10 is specifically an image recognition dataset. The dataset is intended to be used for developing\n",
    "unsupervised feature learning, deep learning, self-taught algorithms. That being said, the primary prediction\n",
    "task is to determine the type of animal or transportation object found in each of the pictures in the Unlabeled folder.\n",
    "Something that should be noted about the \"Unlabeled\" folder, aside from it containing the the classes mentioned above,\n",
    "it additionally includes other types of animals (bears, rabbits, etc.) and transportation objects[trains, buses, etc.).\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u>`Measuring Success`</u>\n",
    "\n",
    "One reason this data is important is if trained correctly & the prediction task is achieved, third parties that\n",
    "use image captcha's for their websites, networks, etc. could use this data as a way to visualize how captcha's can\n",
    "be bypassed by __unsupervised__ feature learning, which essentially defeats the purpose of having a captcha test.\n",
    "\n",
    "In order for this data to be of use to third parties using captcha's, I believe the prediction algorithm will\n",
    "have to render at least an 80% accuracy. The reason it isn't 90% is because if the prediction algorithm selects a\n",
    "wrong image, or doesn't recognize an image, often times captcha test's will let you get away with about 2 or less errors.\n",
    "\n",
    "- Choose & explain what metric(s) I will use to evaluate my algorithmâ€™s performance.\n",
    "- I should give a detailed argument for why this (these) metric(s) are appropriate on your data.\n",
    "- That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task).\n",
    "- (accuracy is RARELY the best evaluation metric to use. Think deeply about an appropriate measure of performance.)\n",
    "\n",
    "\n",
    "-------------------------------------\n",
    "Dataset : [STL-10 Kaggle Dataset](https://www.kaggle.com/jessicali9530/stl10)\n",
    "\n",
    "Question Of Interest : Identify the type of animal or transportation object shown in the picture\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Matrix Shape   :  Before (5000, 96, 96, 3) ----->  After (5000, 27648) \n",
      "\n",
      "Greyscale Matrix Shape  :  Before (5000, 96, 96)    ----->  After (5000, 9216) \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Original Data</th>\n",
       "      <th>Greyscale Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># of Samples</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># of Features</td>\n",
       "      <td>27648</td>\n",
       "      <td>9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image Resolution</td>\n",
       "      <td>96 x 96</td>\n",
       "      <td>96 x 96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># of Channels</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image Size</td>\n",
       "      <td>27648px's</td>\n",
       "      <td>9216px's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Original Data Greyscale Data\n",
       "0      # of Samples          5000           5000\n",
       "1     # of Features         27648           9216\n",
       "2  Image Resolution       96 x 96        96 x 96\n",
       "3     # of Channels             3              1\n",
       "4        Image Size     27648px's       9216px's"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tkinter import Tcl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "with open('../data/stl10_binary/train_y.bin', 'rb') as f:\n",
    "    labels = np.fromfile(f, dtype=np.uint8)\n",
    "\n",
    "with open('../data/stl10_binary/class_names.txt', 'r') as f:\n",
    "    classNames = [line.rstrip() for line in f]\n",
    "\n",
    "# Reading in the dataset (sorted by filename) into a numpy array\n",
    "file_X = list(Tcl().call('lsort', '-dict', glob.glob('../data/STL10/Train/*.png')))\n",
    "rgb_matrix = np.array([np.array(Image.open(file)) for file in file_X])\n",
    "_, h, w, c = rgb_matrix.shape\n",
    "\n",
    "# Create new numpy array w/ re-colored greyscaled images\n",
    "greyscale_matrix = np.array([np.array(Image.open(file).convert(\"L\")) for file in file_X])\n",
    "\n",
    "df = pd.DataFrame({'' : ['# of Samples','# of Features','Image Resolution','# of Channels','Image Size']})\n",
    "df['Original Data']  = [_, h*w*c, '{} x {}'.format(h,w), c, str(h*w*c) + 'px\\'s']\n",
    "df['Greyscale Data']  = [_, h*w, '{} x {}'.format(h,w), 1, str(h*w) + 'px\\'s']\n",
    "\n",
    "rgb_vec = rgb_matrix.reshape((_,h*w*c))\n",
    "greyscale_vec = greyscale_matrix.reshape((_,h*w))\n",
    "\n",
    "print(\"\\nOriginal Matrix Shape   :  Before\", rgb_matrix.shape, \"----->  After\", rgb_vec.shape,\"\\n\")\n",
    "print(\"Greyscale Matrix Shape  :  Before\", greyscale_matrix.shape, \"   ----->  After\",greyscale_vec.shape, \"\\n\\n\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by reading the dataset into a numpy array, but because it contains colored images, it would be optimal\n",
    "to turn it into a grayscale array so we are able to compute faster.\n",
    "\n",
    "Then after doing so, the shape of the original matrix and grayscale are outputted to show the initial dimensions.\n",
    "To the right of these shapes, are the concatenated versions of those matrices.\n",
    "\n",
    "At the bottom a table is created to better understand the differences between the 2 matrices, one containing color\n",
    "pictures and the other one containing greyscaled images. Here, is where we notice the large distance between the image\n",
    "sizes for each matrix. Notice how each greyscaled picture is 3 times smaller than the original color pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Visualizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_gallery(images, titles, h, w, flag, n_row=3, n_col=6):\n",
    "    plt.figure(figsize=(1.7 * n_col, 2.3 * n_row))\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=1.0, hspace=.25)\n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(images[i].reshape((h,w)), cmap=plt.cm.gray)\n",
    "        if flag:\n",
    "            plt.title(classNames[titles[i] - 1], size=12)\n",
    "        if not flag:\n",
    "            plt.title(titles[i], size=12)\n",
    "        plt.xticks(());  plt.yticks(())\n",
    "\n",
    "plot_gallery(greyscale_vec, labels, h, w, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualize 18 images within the greyscale numpy array. This function will be helpful later\n",
    "on to output certain images given a certain certain array.\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Creating Training & Test Data (7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# - Choose the method you will use for dividing your data into training & testing\n",
    "\n",
    "# Split data set (train & fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----------------------------\n",
    "\n",
    "- Explain, Why am I using : a Stratisfied 10-fold cross validation? or Shuffle splits?\n",
    "\n",
    "- Explain why my chosen method is appropriate or use more than one method as appropriate.\n",
    "\n",
    "- Convince me that your cross validation method is a realistic mirroring of how an algorithm would be used in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----------------------------\n",
    "\n",
    "## 2. Modeling\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Training w/ Data Expansion (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# - Setup the training to use data expansion in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Explain why the chosen data expansion techniques are appropriate for my dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Exploring Convolutional Architectures (20%)\n",
    "\n",
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.1 Method 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.) CNN - Variation 1 : Investigate a Convolutional Network Architecture --- (& investigate changing some parameters of each arch\n",
    "# - Create a CNN to use on my data using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.) CNN - Variation 2 : Investigate a Convolutional Network Architecture --- (& investigate changing some parameters of each arch\n",
    "# - Create a CNN to use on my data using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.2 Method 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 1.) CNN - Variation 1 : Investigate a Convolutional Network Architecture --- (& investigate changing some parameters of each arch\n",
    "# - Create a CNN to use on my data using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.) CNN - Variation 2 : Investigate a Convolutional Network Architecture --- (& investigate changing some parameters of each arch\n",
    "# - Create a CNN to use on my data using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Use the method of cross validation & evaluation metric that you argued for at the beginning of the lab.\n",
    "- Visualize the performance of the training & validation sets per iteration (use the \"history\" parameter of Keras)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 (15 points)\n",
    "- Visualize the final results of the CNNs & interpret the performance.\n",
    "- Use proper statistics as appropriate, especially for comparing models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 (10 points)\n",
    "- Compare the performance of my convolutional network to a standard multi-layer perceptron (MLP) using the receiver operating characteristic & area under the curve.\n",
    "- Use proper statistical comparison techniques.\n",
    "\n",
    "\n",
    "### 3. Transfer Learning (10 points)\n",
    "- [1] Use transfer learning to pre-train the weights of my initial layers of my CNN.\n",
    "- [2] Compare the performance when using transfer learning to training from scratch in terms of classification performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### References\n",
    "\n",
    "Kaggle. STL-10. https://www.kaggle.com/jessicali9530/stl10 (Accessed 9-25-2020)\n",
    "\n",
    "Adam Coates, Honglak Lee, Andrew Y. Ng An Analysis of Single Layer Networks in Unsupervised Feature Learning AISTATS, 2011.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
