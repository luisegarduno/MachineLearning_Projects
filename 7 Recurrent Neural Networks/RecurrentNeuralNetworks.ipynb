{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab Assignment Seven: RNNs\n",
    "\n",
    "### Luis Garduno\n",
    "\n",
    "Dataset : [Sentiment140 Kaggle Dataset](https://www.kaggle.com/kazanova/sentiment140) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----------------------------\n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Total Tweets: 200000 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 1579365 to 1333811\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   polarity  200000 non-null  int64 \n",
      " 1   id        200000 non-null  int64 \n",
      " 2   date      200000 non-null  object\n",
      " 3   query     200000 non-null  object\n",
      " 4   user      200000 non-null  object\n",
      " 5   tweet     200000 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "import glob, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from tkinter import Tcl\n",
    "from skimage.io import imshow\n",
    "from sklearn import metrics as mt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Load in Sentiment140 Dataset in pandas array\n",
    "df = pd.read_csv('../data/Sentiment140/training.1600000.processed.noemoticon.csv',\n",
    "                 names=['polarity', 'id', 'date', 'query', 'user', 'tweet'],\n",
    "                 encoding='ISO-8859-1')\n",
    "\n",
    "# Create sample (Remove later)\n",
    "df = df.sample(frac=1)\n",
    "df = df[:200000]\n",
    "\n",
    "print(\"Number of Total Tweets:\", len(df), \"\\n\")\n",
    "\n",
    "# Check if our dataset is missing any columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Field | Description | Type |\n",
    "| ----- | ----------- | ---- |\n",
    "| **Polarity** | &nbsp;&nbsp;&nbsp; - The target/polarity of the tweet <br /> &nbsp;&nbsp; [0] Negative; [2] Neutral; [4] Positive; | Discrete |\n",
    "| **id**    | &nbsp;&nbsp;&nbsp; - The id of the tweet    | Discrete |\n",
    "| **date**  | &nbsp;&nbsp;&nbsp; - The date of the tweet  | Interval |\n",
    "| **query** | &nbsp;&nbsp;&nbsp; - The query | Nominal |\n",
    "| **user**  | &nbsp;&nbsp;&nbsp; - The user that tweeted  | nominal  |\n",
    "| **tweet**  | &nbsp;&nbsp;&nbsp; - The text of the tweet  | nominal  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polarity         2\n",
       "id          199978\n",
       "date        175217\n",
       "query            1\n",
       "user        148449\n",
       "tweet       199135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as mn\n",
    "\n",
    "# Check for any missing/null values within dataset\n",
    "mn.matrix(df)\n",
    "\n",
    "# Find unique values within each field, before dropping columns.\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After outputting all of the unique values, we see that there is only 1 unique value\n",
    "within the query field, meaning that it will not make an impact when further doing\n",
    "our analysis because all the values are the same. Other fields that can be dropped\n",
    "are the user tweet id, username, iand date because these these do not impact whether a\n",
    "user's tweet is negative or positive.\n",
    "\n",
    "Addtionally we're able to see that there's 2 unique values within the polarity field,\n",
    "it is probably best to find out what these two values are and change them so that 0\n",
    "equals negative and 1 equals positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the fields we don't need\n",
    "df.drop(['id', 'date', 'query','user'], axis=1, inplace=True)\n",
    "\n",
    "# Find the 2 unique polarity fields\n",
    "df['polarity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of Tweets')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change [4] to [1] so the data is easier to understand.\n",
    "df['polarity'] = df['polarity'].replace(4,1)\n",
    "\n",
    "# Visualize whether data is evenly divided in terms of the polarity of tweets.\n",
    "ax = sns.countplot(x=\"polarity\", data=df, palette=['red', 'blue'])\n",
    "ax.set_title('Distribution in Polarity within Tweets')\n",
    "ax.set_xlabel('Polarity')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels(['[0] Negative', '[1] Positive'])\n",
    "ax.set_ylabel('Number of Tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 200000 entries, 1579365 to 1333811\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   polarity  200000 non-null  int64 \n",
      " 1   tweet     200000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check for proper variable representations\n",
    "# Make all tweets lowercase for future processing\n",
    "df['tweet'] = df['tweet'].astype('str')\n",
    "df['tweet'] = df['tweet'].str.lower()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Text/Word Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section I used some of the most common text-preprocessing that are practiced\n",
    "in Natural Language Processing projects such as:     \n",
    "- Removing stop words     \n",
    "- Stemming words     \n",
    "- Lemmatizing words\n",
    "- Tokenizing individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1579365</th>\n",
       "      <td>1</td>\n",
       "      <td>plane going new york city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498399</th>\n",
       "      <td>0</td>\n",
       "      <td>someone video taking forever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355117</th>\n",
       "      <td>0</td>\n",
       "      <td>tired work tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666097</th>\n",
       "      <td>0</td>\n",
       "      <td>never gone school trip never lol bad mum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399376</th>\n",
       "      <td>0</td>\n",
       "      <td>still possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475934</th>\n",
       "      <td>0</td>\n",
       "      <td>miss epically long blonde sophomore hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007452</th>\n",
       "      <td>1</td>\n",
       "      <td>clean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867646</th>\n",
       "      <td>1</td>\n",
       "      <td>back jakarta bus ride plane today yay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862718</th>\n",
       "      <td>1</td>\n",
       "      <td>damp rather damp shall make delicious mexican ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468446</th>\n",
       "      <td>0</td>\n",
       "      <td>rain pours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100637</th>\n",
       "      <td>1</td>\n",
       "      <td>gon na eat dinner bye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332898</th>\n",
       "      <td>1</td>\n",
       "      <td>yeah canadian province comm little le u steady...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808831</th>\n",
       "      <td>1</td>\n",
       "      <td>sitting couch thinking much study thinking cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523260</th>\n",
       "      <td>1</td>\n",
       "      <td>temperamental good anyway watching taking pelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411519</th>\n",
       "      <td>1</td>\n",
       "      <td>okeley dokers nice talking sleep tight pleasan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847777</th>\n",
       "      <td>1</td>\n",
       "      <td>bought bought bike since 10 year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552266</th>\n",
       "      <td>1</td>\n",
       "      <td>girl crazy always bring buddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474453</th>\n",
       "      <td>0</td>\n",
       "      <td>talk soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183414</th>\n",
       "      <td>1</td>\n",
       "      <td>big fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308722</th>\n",
       "      <td>1</td>\n",
       "      <td>need update starting tomorrow tweet atleast da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity                                              tweet\n",
       "1579365         1                          plane going new york city\n",
       "498399          0                       someone video taking forever\n",
       "355117          0                                tired work tomorrow\n",
       "666097          0           never gone school trip never lol bad mum\n",
       "399376          0                                     still possible\n",
       "475934          0           miss epically long blonde sophomore hair\n",
       "1007452         1                                              clean\n",
       "867646          1              back jakarta bus ride plane today yay\n",
       "862718          1  damp rather damp shall make delicious mexican ...\n",
       "468446          0                                         rain pours\n",
       "1100637         1                              gon na eat dinner bye\n",
       "1332898         1  yeah canadian province comm little le u steady...\n",
       "808831          1  sitting couch thinking much study thinking cup...\n",
       "1523260         1  temperamental good anyway watching taking pelh...\n",
       "1411519         1  okeley dokers nice talking sleep tight pleasan...\n",
       "847777          1               bought bought bike since 10 year old\n",
       "1552266         1                      girl crazy always bring buddy\n",
       "474453          0                                          talk soon\n",
       "1183414         1                                           big fish\n",
       "1308722         1  need update starting tomorrow tweet atleast da..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============ 1.) Removing HTML Tags, URLs, HashTags, Email Addresses, & tagged usernames with RegEx\n",
    "\n",
    "# Parse through each of the tweets by using regular expressions to remove specific parts of the text\n",
    "# RegEx Reference: https://github.com/alvations/nltk/blob/develop/nltk/tokenize/casual.py#L122\n",
    "char_rm = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "hashtag, username=r\"\"\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\"\"\", r\"\"\"(?:@[\\w_]+)\"\"\"\n",
    "emailAddr,htmlTags,=r\"\"\"[\\w.+-]+@[\\w-]+\\.(?:[\\w-]\\.?)+[\\w-]\"\"\", r\"\"\"<[^>\\s]+>\"\"\"\n",
    "urls=r\"\"\"(?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:[a-z]{2,13})/)(?:[^\\s()<>\n",
    "    {}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]\n",
    "    +\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:\n",
    "    [.\\-][a-z0-9]+)*[.](?:[a-z]{2,13})\\b/?(?!@))\"\"\"\n",
    "\n",
    "# Remove : hashtags, usernames, htmltags\n",
    "df['tweet'] = df['tweet'].replace(urls, \"\" ,regex=True)\n",
    "df['tweet'] = df['tweet'].replace(username, \"\" ,regex=True)\n",
    "df['tweet'] = df['tweet'].replace(hashtag, \"\" ,regex=True)\n",
    "df['tweet'] = df['tweet'].replace(htmlTags, \"\" ,regex=True)\n",
    "\n",
    "\n",
    "\n",
    "# ============ 2.) Tokenizing words, removing stop words, changing words back to their stem word and lemmatizing words\n",
    "\n",
    "# The following code was modeled after a snippet of code here:\n",
    "# https://www.traindex.io/blog/event-driven-data-pipelines-in-aws-480i/\n",
    "def preprocess(tweet, stem=False):\n",
    "    # Remove link, user and special characters\n",
    "    tweet = re.sub(char_rm, ' ', str(tweet)).strip()\n",
    "    tweet_token = word_tokenize(tweet)\n",
    "    tokens = []\n",
    "    for token in tweet_token:\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    finalwords=[]\n",
    "    for w in tokens:\n",
    "        if len(w)>1:\n",
    "            word = wordLemm.lemmatize(w)\n",
    "            finalwords.append(word)\n",
    "    return ' '.join(finalwords)\n",
    "\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: preprocess(x))\n",
    "\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For my final dataset that I will be using for my classification problem, in regards of\n",
    "predicting whether a tweet is positive or negative, I selected to use only 2 columns:\n",
    "- Polarity : Whether a tweet in negative or positive ([0] negative; [1] Positive;)\n",
    "- Tweet : The text of a given tweet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Choosing a Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for metrics, for this specific classification problem, it is very easy to\n",
    "know that I will be using accuracy as a metric to evaluate my algorithms's \n",
    "performance.It will use binary cross entropy as it's loss function given\n",
    "the values of the polarity column are 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.4 Creating Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72776 unique tokens. Distilled to 72776 top words.\n",
      "Shape of data tensor: (200000, 1000)\n",
      "Shape of label tensor: (200000, 2)\n",
      "72776\n",
      "Total words 72777\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'polarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-fccb0528cf96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mMAX_WORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mMAX_REV_LENGTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_REV_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_REV_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m    154\u001b[0m           \u001b[0;32mor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcase\u001b[0m \u001b[0mof\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m   return sequence.pad_sequences(\n\u001b[0m\u001b[1;32m    157\u001b[0m       \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m       padding=padding, truncating=truncating, value=value)\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.8/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'polarity'"
     ]
    }
   ],
   "source": [
    "# - Choose the method I'll use for dividing my data into training and testing (i.e., am I  using Stratified 10-fold cross validation? Shuffle splits? Why?).\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Method 1 Splits Dataset into Training and Testing set\n",
    "# X_train, X_test = train_test_split(df, test_size=0.2 ,random_state=7) \n",
    "# print(\"Train Data size:\", len(X_train))\n",
    "# print(\"Test Data size:\", len(X_test))\n",
    "\n",
    "NUM_TOP_WORDS = None # use entire vocabulary!\n",
    "MAX_ART_LEN = 1000 # maximum and minimum number of words\n",
    "\n",
    "#tokenize the text\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(df.tweet)\n",
    "# save as sequences with integers replacing words\n",
    "sequences = tokenizer.texts_to_sequences(df.tweet)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=MAX_ART_LEN)\n",
    "\n",
    "y_ohe = keras.utils.to_categorical(df.polarity)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y_ohe.shape)\n",
    "print(np.max(X))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['tweet'])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)\n",
    "\n",
    "# Applying 80/20 split \n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=101)\n",
    "\n",
    "MAX_WORDS = 10000\n",
    "MAX_REV_LENGTH = 30\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_REV_LENGTH)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_REV_LENGTH)\n",
    "\n",
    "#X, y = df['tweet'], df['polarity']\n",
    "\n",
    "#tfidf_vect = TfidfVectorizer()\n",
    "#X = tfidf_vect.fit_transform(X)\n",
    "\n",
    "# convert to pandas to get a better view/understanding\n",
    "#df_New = pd.DataFrame(data=X.toarray(),columns=tfidf_vect.get_feature_names())\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=47)\n",
    "#le.fit(X_train['polarity'].unique.tolist())\n",
    "le.fit(X_train['polarity'].tolist())\n",
    "\n",
    "y_train = le.transform(X_train['polarity'].tolist())\n",
    "y_test = le.transform(X_test['polarity'].tolist())\n",
    "\n",
    "y_train, y_test = y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "\n",
    "print(\"======= Train Shapes ======\")\n",
    "print('Train :', X_train.shape, '\\nTest  :', y_train.shape)\n",
    "print(\"\\n====== Testing Shapes ======\")\n",
    "print('Train :', X_test.shape, '\\nTest  :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Explain why my chosen method is appropriate or use more than one method as appropriate.\n",
    "- Convince me that my cross validation method is a realistic mirroring of how an algorithm would be used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-----------------------------\n",
    "\n",
    "## 2. Modeling | You're @ a C, keep going bro.\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Exploring Recurrent Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras libraries\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import average, Reshape, Input, Add, SimpleRNN\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GRU\n",
    "from tensorflow.keras.layers import SeparableConv2D, BatchNormalization, LSTM\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, concatenate\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph comparing Training & Validation Vs. Accuracy & Training loss\n",
    "def getChart(h):\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    \n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.title('Training')\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.plot(h.history['val_accuracy'])\n",
    "    plt.title('Validation')\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    plt.plot(h.history['val_loss'])\n",
    "    plt.xlabel('epochs')\n",
    "\n",
    "# Graph comparing Training & Validation Vs. Accuracy & Training loss\n",
    "def getCharts(h1, h2, h3, h4):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,2,1)\n",
    "    ax1 = sns.lineplot(data=h1.history['accuracy'], label='LeNet - AdaM', color='blue')\n",
    "    sns.lineplot(data=h2.history['accuracy'], label='LeNet - RMSProp', color='red')\n",
    "    sns.lineplot(data=h3.history['accuracy'], label='Xception - AdaM', color='green')\n",
    "    sns.lineplot(data=h4.history['accuracy'], label='Xception - RMSProp ', color='darkorange')\n",
    "    \n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.title('Training')\n",
    "    plt.subplot(2,2,2)\n",
    "    ax2 = sns.lineplot(data=h1.history['val_accuracy'], label='LeNet - AdaM', color='blue')\n",
    "    sns.lineplot(data=h2.history['val_accuracy'], label='LeNet - RMSProp', color='red')\n",
    "    sns.lineplot(data=h3.history['val_accuracy'], label='Xception - AdaM', color='green')\n",
    "    sns.lineplot(data=h4.history['val_accuracy'], label='Xception - RMSProp', color='darkorange')\n",
    "    plt.title('Validation')\n",
    "    \n",
    "    plt.subplot(2,2,3)\n",
    "    ax3 = sns.lineplot(data=h1.history['loss'], label='LeNet - AdaM', color='blue')\n",
    "    sns.lineplot(data=h2.history['loss'], label='LeNet - RMSProp', color='red')\n",
    "    sns.lineplot(data=h3.history['loss'], label='Xception - AdaM', color='green')\n",
    "    sns.lineplot(data=h4.history['loss'], label='Xception - RMSProp', color='darkorange')\n",
    "    plt.ylabel('Training Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    \n",
    "    plt.subplot(2,2,4)\n",
    "    ax4 = sns.lineplot(data=h1.history['val_loss'], label='LeNet - AdaM', color='blue')\n",
    "    sns.lineplot(data=h2.history['val_loss'], label='LeNet - RMSProp', color='red')\n",
    "    sns.lineplot(data=h3.history['val_loss'], label='Xception - AdaM', color='green')\n",
    "    sns.lineplot(data=h4.history['val_loss'], label='Xception - RMSProp', color='darkorange')\n",
    "    plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.1 Method 1: GRU Architecture (45%)\n",
    "\n",
    "A Gated Recurrent Network, or GRU\n",
    "- Be sure to use an embedding layer (pre-trained, from scratch, OR both).\n",
    "- Adjust hyper-parameters of the networks as needed to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "######################## GRU Style Architecture : AdaM ##########################\n",
    "#################################################################################\n",
    "max_words = 10000\n",
    "max_length = 30\n",
    "shpe = (max_length,)\n",
    "embed_Size = 50\n",
    "rnn_StateSize = 100\n",
    "\n",
    "rnns = []\n",
    "input_holder = Input(shape=(X_train.shape[1], ))\n",
    "shared_embed = Embedding(max_words,             # input dimension (max int of OHE)\n",
    "                embed_Size,                     # output dimension size\n",
    "                input_length=max_length)(input_holder) # number of words in each sequence\n",
    "\n",
    "\n",
    "\n",
    "# create GRU\n",
    "x1 = GRU(rnn_StateSize, dropout=0.2, recurrent_dropout=0.2)(shared_embed)\n",
    "x1 = Dense(1, activation='sigmoid')(x1)\n",
    "gru_1 = Model(inputs=input_holder,outputs=x1)\n",
    "\n",
    "print(gru_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "opt1 = Adam(lr=0.0001, epsilon=0.0001, clipnorm=1.0)\n",
    "gru_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_GRU1 = gru_1.fit(X_train, y_train_ohe, batch_size=128, \n",
    "                         epochs=50, verbose=1, validation_data=(X_test,y_test_ohe),\n",
    "                         callbacks=[EarlyStopping(monitor='val_loss', patience=4)])\n",
    "\n",
    "yhat = np.round(gru_1.predict(X_test))\n",
    "print(mt.classification_report(y_test_ohe, yhat, zero_division=0))\n",
    "getChart(history_GRU1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to use an embedding layer (pre-trained, from scratch, OR both).\n",
    "# Adjust hyper-parameters of the networks as needed to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "######################## GRU Style Architecture : RMSProp #######################\n",
    "#################################################################################\n",
    "\n",
    "shared_embed = Embedding(max_words,             # input dimension (max int of OHE)\n",
    "                embed_Size,                     # output dimension size\n",
    "                input_length=max_length)(input_holder) # number of words in each sequence\n",
    "\n",
    "\n",
    "\n",
    "# create GRU\n",
    "x1 = GRU(rnn_StateSize, dropout=0.2, recurrent_dropout=0.2)(shared_embed)\n",
    "x1 = Dense(1, activation='sigmoid')(x1)\n",
    "gru_1 = Model(inputs=input_holder,outputs=x1)\n",
    "\n",
    "opt = Adam(lr=0.0001, epsilon=0.0001, clipnorm=1.0)\n",
    "\n",
    "print(gru_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "opt2 = Adam(lr=0.0001, epsilon=0.0001, clipnorm=1.0)\n",
    "gru_2.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "history_GRU2 = gru_2.fit(X_train, y_train_ohe, batch_size=128,\n",
    "                         epochs=50, verbose=1, validation_data=(X_test,y_test_ohe),\n",
    "                         callbacks=[EarlyStopping(monitor='val_loss', patience=4)])\n",
    "\n",
    "yhat = np.round(gru_2.predict(X_test))\n",
    "print(mt.classification_report(y_test_ohe, yhat, zero_division=0))\n",
    "getChart(history_GRU2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to use an embedding layer (pre-trained, from scratch, OR both).\n",
    "# Adjust hyper-parameters of the networks as needed to improve generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2.2 Method 2: LTSM  Architecture (60%)\n",
    "\n",
    "A \"long short-term memory\" units, or LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "######################## LSTM Style Architecture : AdaM ##########################\n",
    "##################################################################################\n",
    "shpe = (h,w,1)\n",
    "max_words = 10000\n",
    "max_length = 30\n",
    "shpe = (max_length,)\n",
    "l2_lambda = 0.000001\n",
    "\n",
    "input_holder = Input(shape=shpe, dtype='int32')\n",
    "\n",
    "# Embedding Layer ================================================================\n",
    "x3 = Embedding(vocab_size, EMBEDDING_DIM, weights=[embedding_matrix],\n",
    "               input_length=max_length,\n",
    "               trainable=False)(input_holder)\n",
    "\n",
    "# Spatial Dropout Layer ==========================================================\n",
    "x3 = SpatialDropout1D(0.2)(x3)\n",
    "x3 = Activation('relu')(x3)\n",
    "\n",
    "# Convolution Layer ==============================================================\n",
    "x3 = Conv1D(64,5)(x3)\n",
    "\n",
    "# LSTM Layer =====================================================================\n",
    "x3 = LSTM(64, dropout=0.2, recurrent_dropout=0.2)(x3)\n",
    "\n",
    "# Bidirectional Layer ============================================================\n",
    "x3 = Bidirectional(x3)(x3)\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "x3 = Dense(512)(x3)\n",
    "x3 = Dropout(0.5)(x3)\n",
    "\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "x3 = Dropout(0.5)(x3)\n",
    "\n",
    "x3 = Activation(\"relu\")(x3)\n",
    "x3 = Dense(512)(x3)\n",
    "\n",
    "x3 = Activation(\"sigmoid\")(x3)\n",
    "x3 = Dense(1)(x3)\n",
    "\n",
    "lstm_1 = Model(inputs=input_holder,outputs=x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lstm_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history_LSTM1 = lstm_1.fit(X_train, y_train_ohe, batch_size=128,\n",
    "                           epochs=50, verbose=1, validation_data=(X_test,y_test_ohe),\n",
    "                           callbacks=[EarlyStopping(monitor='val_loss', patience=4)])\n",
    "\n",
    "yhat = np.round(lstm_1.predict(X_test))\n",
    "print(mt.classification_report(y_test_ohe, yhat, zero_division=0))\n",
    "getChart(history_LSTM1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be sure to use an embedding layer (pre-trained, from scratch, OR both).\n",
    "# Adjust hyper-parameters of the networks as needed to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "######################## LSTM Style Architecture : RMSProp #######################\n",
    "##################################################################################\n",
    "\n",
    "\n",
    "# - Using the best RNN parameters & architecture, add a second recurrent chain to my RNN.\n",
    "# - The input to the second chain should be the output sequence of the first chain.\n",
    "   \n",
    "# Embedding Layer ================================================================\n",
    "x4 = Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "               input_length=max_length, weights=[embedding_matrix],\n",
    "               trainable=False)(x4)\n",
    "\n",
    "# Bidirectional Layer ============================================================ \n",
    "# x4 = LSTM(64,dropout=0.3,return_sequences=True)(x4)\n",
    "# x4 = Bidirectional(x4)(x4)\n",
    "x4 = Bidirectional(LSTM(64,dropout=0.3,return_sequences=True)),\n",
    "x4 = Dropout(0.3),\n",
    "\n",
    "\n",
    "# Bidirectional Layer ============================================================ \n",
    "# x4 = Dropout(0.3)(x4)\n",
    "# x4 = LSTM(64)(x4)\n",
    "# x4 = Bidirectional(x4)(x4)\n",
    "x4 = Bidirectional(LSTM(64,dropout=0.3))(x4)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "\n",
    "x4 = Activation(\"relu\")(x4)\n",
    "x4 = Dense(512)(x4)\n",
    "x4 = Dropout(0.3)(x4)\n",
    "                  \n",
    "x4 = Activation(\"sigmoid\")(x4)\n",
    "x4 = Dense(1)(x4)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lstm_2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history_LSTM2 = lstm_2.fit(X_train, y_train_ohe, batch_size=128,\n",
    "                           epochs=50, verbose=1, validation_data=(X_test,y_test_ohe),\n",
    "                           callbacks=[EarlyStopping(monitor='val_loss', patience=4)])\n",
    "\n",
    "yhat = np.round(lstm_2.predict(X_test))\n",
    "print(mt.classification_report(y_test_ohe, yhat, zero_division=0))\n",
    "getChart(history_LSTM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Be sure to use an embedding layer (pre-trained, from scratch, OR both).\n",
    "# Adjust hyper-parameters of the networks as needed to improve generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Discuss the performance of each network & compare them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Adding a 2nd recurrent chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Using the best RNN parameters & architecture, add a second recurrent chain to my RNN.\n",
    "# The input to the second chain should be the output sequence of the first chain.\n",
    "# Visualize the performance of training & validation sets versus the training iterations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# - Use the method of cross validation & evaluation criteria that I argued for at the beginning of the lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# - Visualize the results of all the RNNs I trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use proper statistical comparison techniques to determine which method(s) is (are) superior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "----------------------------------------\n",
    "\n",
    "### 3. t-SNE or RNN generating novel text\n",
    "You have free reign to provide additional analyses. Ideas:\n",
    "\n",
    "- Option 1: Use t-SNE (or SVD or PCA or UMAP) to visualize the word embeddings of a subset of words in your vocabulary.\n",
    "    - Try to interpret what each dimension reflects (in your own words).\n",
    "    - That is, try to explain what aspect of the language is encoded in the reduced dimensionality embedding.\n",
    "\n",
    "- Options 2: Use the ConceptNet Numberbatch embedding & compare to GloVe\n",
    "\n",
    "- Another Idea (NOT required): Try to create a RNN for generating novel text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
