{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lonely-configuration",
   "metadata": {},
   "source": [
    "# Population Prediction\n",
    "\n",
    "### Luis Garduno\n",
    "\n",
    "## 1. Business Understanding\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u><code>About the datasets:</code></u>\n",
    "    \n",
    "    In order to generate the most accurate prediction of earth's population in 2122, it's\n",
    "    necessary to have population data for as many previous years as possible.\n",
    "    \n",
    "    The dataset that will be used will be a combination of 2 different datasets. The first\n",
    "    dataset contains the global population data from 1951 to 2020, whereas the second\n",
    "    dataset contains the each country's population data from 2021 to present time. \n",
    "\n",
    "-------------------------------------\n",
    "    \n",
    "Datasets [Kaggle]: \n",
    "1. [__World Population by Year (1951 - 2020)__](https://www.kaggle.com/sansuthi/world-population-by-year)\n",
    "2. [__World Population (2021 - Present)__](https://www.kaggle.com/rsrishav/world-population)\n",
    "\n",
    "Question Of Interest : Predict the population of earth in 2122.\n",
    "    \n",
    "-------------------------------------\n",
    "\n",
    "## 2. Data Understanding\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "proprietary-consultation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Dataset #1 (1951 - 2020) ***********\n",
      "\n",
      "--> Columns: ['Year' 'Population' 'ChangePerc' 'NetChange' 'Density' 'Urban'\n",
      " 'UrbanPerc']\n",
      "\n",
      "\n",
      "*********** Dataset #2 (2021 - Present) ***********\n",
      "\n",
      "--> Columns: ['iso_code' 'country' '2021_last_updated' '2020_population' 'area'\n",
      " 'density_sq_km' 'growth_rate' 'world_%' 'rank']\n",
      "*********** Dataset #3 (1951 - Present) ***********\n",
      "\n",
      "--> Columns: ['#YR' 'TFR' 'SRB' 'RNI' 'POP95_99' 'POP90_94' 'POP85_89' 'POP80_84'\n",
      " 'POP75_79' 'POP70_74' 'POP65_69' 'POP60_64' 'POP5_9' 'POP55_59'\n",
      " 'POP50_54' 'POP45_49' 'POP40_44' 'POP35_39' 'POP30_34' 'POP25_29'\n",
      " 'POP20_24' 'POP15_19' 'POP10_14' 'POP100_' 'POP0_4' 'POP' 'NMR' 'NAME'\n",
      " 'MR1_4' 'MR0_4' 'MPOP95_99' 'MPOP90_94' 'MPOP85_89' 'MPOP80_84'\n",
      " 'MPOP75_79' 'MPOP70_74' 'MPOP65_69' 'MPOP60_64' 'MPOP5_9' 'MPOP55_59'\n",
      " 'MPOP50_54' 'MPOP45_49' 'MPOP40_44' 'MPOP35_39' 'MPOP30_34' 'MPOP25_29'\n",
      " 'MPOP20_24' 'MPOP15_19' 'MPOP10_14' 'MPOP100_' 'MPOP0_4' 'MPOP' 'MMR1_4'\n",
      " 'MMR0_4' 'IMR_M' 'IMR_F' 'IMR' 'GRR' 'GR' 'FPOP95_99' 'FPOP90_94'\n",
      " 'FPOP85_89' 'FPOP80_84' 'FPOP75_79' 'FPOP70_74' 'FPOP65_69' 'FPOP60_64'\n",
      " 'FPOP5_9' 'FPOP55_59' 'FPOP50_54' 'FPOP45_49' 'FPOP40_44' 'FPOP35_39'\n",
      " 'FPOP30_34' 'FPOP25_29' 'FPOP20_24' 'FPOP15_19' 'FPOP10_14' 'FPOP100_'\n",
      " 'FPOP0_4' 'FPOP' 'FMR1_4' 'FMR0_4' 'GENC' 'FIPS' 'E0_M' 'E0_F' 'E0' 'CDR'\n",
      " 'CBR' 'ASFR45_49' 'ASFR40_44' 'ASFR35_39' 'ASFR30_34' 'ASFR25_29'\n",
      " 'ASFR20_24' 'ASFR15_19' 'AREA_KM2' 'POP_DENS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load each of the datasets into a dataframe\n",
    "\n",
    "print(\"*********** Dataset #1 (1951 - 2020) ***********\\n\")\n",
    "df_1 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/world-population_1.csv')\n",
    "print(\"--> Columns:\", df_1.columns.values)\n",
    "#print(df_1.info())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"*********** Dataset #2 (2021 - Present) ***********\\n\")\n",
    "df_2 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/world-population_2.csv')\n",
    "print(\"--> Columns:\", df_2.columns.values)\n",
    "#print(df_2.info())\n",
    "\n",
    "print(\"*********** Dataset #3 (1951 - Present) ***********\\n\")\n",
    "df_3 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/idb5yr.all', delimiter='|', encoding='ISO-8859-1')\n",
    "print(\"--> Columns:\", df_3.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-privilege",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "Printing out the information about the dataframe we are able to see that there are a\n",
    "total of 7 attributes in the first dataset, and 8 in the second.\n",
    "\n",
    "Attributes includes:\n",
    "- Description\n",
    "\n",
    "Below is a brief description of some of the key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "about-extra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-138-ce29b4d0be8d>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_4[\"POP\"][cnt] = df_4[\"POP\"][cnt] + df_3[\"POP\"][i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7831718605.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2003</td>\n",
       "      <td>6.369187e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2004</td>\n",
       "      <td>6.448262e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2005</td>\n",
       "      <td>6.527057e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2006</td>\n",
       "      <td>6.607396e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2007</td>\n",
       "      <td>6.689442e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2008</td>\n",
       "      <td>6.773320e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2009</td>\n",
       "      <td>6.857161e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2010</td>\n",
       "      <td>6.939762e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2011</td>\n",
       "      <td>7.022085e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2012</td>\n",
       "      <td>7.105002e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2013</td>\n",
       "      <td>7.188529e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2014</td>\n",
       "      <td>7.271599e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2015</td>\n",
       "      <td>7.353476e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2016</td>\n",
       "      <td>7.435151e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2017</td>\n",
       "      <td>7.516770e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018</td>\n",
       "      <td>7.597066e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019</td>\n",
       "      <td>7.676686e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2020</td>\n",
       "      <td>7.756873e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2021</td>\n",
       "      <td>7.831719e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2022</td>\n",
       "      <td>7.905337e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR           POP\n",
       "52  2003  6.369187e+09\n",
       "53  2004  6.448262e+09\n",
       "54  2005  6.527057e+09\n",
       "55  2006  6.607396e+09\n",
       "56  2007  6.689442e+09\n",
       "57  2008  6.773320e+09\n",
       "58  2009  6.857161e+09\n",
       "59  2010  6.939762e+09\n",
       "60  2011  7.022085e+09\n",
       "61  2012  7.105002e+09\n",
       "62  2013  7.188529e+09\n",
       "63  2014  7.271599e+09\n",
       "64  2015  7.353476e+09\n",
       "65  2016  7.435151e+09\n",
       "66  2017  7.516770e+09\n",
       "67  2018  7.597066e+09\n",
       "68  2019  7.676686e+09\n",
       "69  2020  7.756873e+09\n",
       "70  2021  7.831719e+09\n",
       "71  2022  7.905337e+09"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df_3.rename(columns={'#YR':'YEAR'}, inplace=True)\n",
    "\n",
    "for col in df_3.columns.values:\n",
    "    if col != 'YEAR' and col != 'POP':\n",
    "        df_3.drop(col, axis=1, inplace=True)\n",
    "\n",
    "df_4 = pd.DataFrame({'YEAR': list(range(1951, 2023)), 'POP': np.zeros((72))})\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(df_3)):\n",
    "    yr = df_3[\"YEAR\"][i]\n",
    "    #print(df_3[\"YEAR\"][i])\n",
    "    \n",
    "    if cnt <= 71 and yr > 1950 and yr <= 2022:\n",
    "        yr2 = df_4[\"YEAR\"][cnt]\n",
    "        if yr2 == yr:\n",
    "            df_4[\"POP\"][cnt] = df_4[\"POP\"][cnt] + df_3[\"POP\"][i]\n",
    "            cnt += 1\n",
    "            if cnt == 72: cnt = 0\n",
    "        \n",
    "    \n",
    "    #print(df_)\n",
    "    #print(df_4[\"YEAR\" == df_3[\"YEAR\"][i]])\n",
    "    #print(i)\n",
    "\n",
    "\n",
    "#cur = 1951\n",
    "#for yr in range(0,70):\n",
    "#    df_4['YEAR'][yr] = cur\n",
    "#    cur += 1\n",
    "    #df_4.loc[cnt,\"YEAR\"] = cur\n",
    "    #df_4[yr][]\n",
    "    \n",
    "    #print(yr, df_4['YEAR'][yr])\n",
    "#for yr in df_4:\n",
    "#    print(yr)\n",
    "#    df_4[yr]\n",
    "#    df_4[yr] = cur\n",
    "#    cur += 1\n",
    "#for yr in range(1951, 2022):\n",
    "#    df_4[\"YEAR\" == yr] = 0\n",
    "#df\n",
    "#for yr in range(1951, 2022):\n",
    "    \n",
    "\n",
    "\n",
    "# describe dataframe\n",
    "#df_4.describe()\n",
    "#df_4.info()\n",
    "print(df_4[\"POP\"][70])\n",
    "df_4.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-tender",
   "metadata": {},
   "source": [
    "| Variable | Description | Type | Range |\n",
    "| -------- | ----------- | ---- | ----- |\n",
    "| A        | B           | C    | D     |   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-shareware",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-wesley",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Data Quality\n",
    "\n",
    "Using the `missingno` package, we are able to additionally confirm that all the data is complete and there is no missing entries with the dataset. If there was missing data, we could impute the missing values by using the k-nearest neighbor. But if an instance was missing a majority of its attributes, it would be removed from the dataset.\n",
    "\n",
    "The number of unique values in the column \" \" is printed to verify that all instances\n",
    "are weighted equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-terry",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\n",
    "# Given as to how\n",
    "\n",
    "\n",
    "\n",
    "del df['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-merchandise",
   "metadata": {},
   "source": [
    "\n",
    "-------------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.5 Creating Training & Test Data\n",
    "Using Scikit-learn's [cross-validation modules](https://scikit-learn.org/stable/modules/cross_validation.html) we are able to split our dataset for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X data & y target dataframe's\n",
    "y = df[''].values\n",
    "# del df['']\n",
    "X = df.to_numpy()\n",
    "\n",
    "\n",
    "# Divide the data: 80% Training & 20% Testing.  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training Set\", \"\\n   - Data Shape:\",X_train.shape,\"\\n   - Target Shape:\",y_train.shape)\n",
    "print(\"\\nTesting Set\",\"\\n   - Data Shape:\",X_test.shape ,\"\\n   - Target Shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-sword",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "We perform a split within our dataset: 80% will be used for training, and 20% for testing. The 80/20 split is appropriate for\n",
    "the dataset because recall that the end goal is for users to be able to determine the probabilities of the earth's population 100 years from now.\n",
    "\n",
    "\n",
    "--------------------\n",
    "\n",
    "## 3. Modeling\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-banking",
   "metadata": {},
   "source": [
    "\n",
    "----------------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2 Custom Classifier Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-synthesis",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "\n",
    "## 4. Deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-marshall",
   "metadata": {},
   "source": [
    "\n",
    "---------------------\n",
    "\n",
    "#### References\n",
    "\n",
    "Worldometer. World Population by Year. https://www.worldometers.info/world-population/world-population-by-year/ (Accessed 01-22-2022)\n",
    "\n",
    "Scikit-learn. Cross-validation. https://scikit-learn.org/stable/modules/cross_validation.html (Accessed 01-22-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-boost",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
