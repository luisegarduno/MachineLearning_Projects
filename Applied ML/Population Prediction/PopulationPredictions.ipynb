{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mature-hearing",
   "metadata": {},
   "source": [
    "# Population Prediction\n",
    "\n",
    "### Luis Garduno\n",
    "\n",
    "## 1. Business Understanding\n",
    "\n",
    "#### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <u><code>About the datasets:</code></u>\n",
    "    \n",
    "    In order to generate the most accurate prediction of earth's population in 2122, it's\n",
    "    better to have population data for as many previous years as possible.\n",
    "    \n",
    "    The dataset that will be used will be a combination of 2 different datasets. The first\n",
    "    dataset contains the global population data from 1951 to 2020, whereas the second\n",
    "    dataset contains the each country's population data from 2021 to present time. \n",
    "\n",
    "-------------------------------------\n",
    "    \n",
    "Datasets [Kaggle]: \n",
    "1. [__World Population by Year (1951 - 2020)__](https://www.kaggle.com/sansuthi/world-population-by-year)\n",
    "2. [__World Population (2021 - Present)__](https://www.kaggle.com/rsrishav/world-population)\n",
    "3. [__International Database (IDB)__](https://www2.census.gov/programs-surveys/international-programs/about/idb/idbzip.zip)\n",
    "\n",
    "Question Of Interest : Predict the population of earth in 2122.\n",
    "    \n",
    "-------------------------------------\n",
    "\n",
    "## 2. Data Understanding\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diverse-mayor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********** Dataset #1 (1951 - 2020) ***********\n",
      "\n",
      "--> Columns: ['Year' 'Population' 'ChangePerc' 'NetChange' 'Density' 'Urban'\n",
      " 'UrbanPerc']\n",
      "\n",
      "\n",
      "*********** Dataset #2 (2021 - Present) ***********\n",
      "\n",
      "--> Columns: ['iso_code' 'country' '2021_last_updated' '2020_population' 'area'\n",
      " 'density_sq_km' 'growth_rate' 'world_%' 'rank']\n",
      "\n",
      "\n",
      "*********** Dataset #3 (1951 - Present) ***********\n",
      "\n",
      "--> Columns: ['#YR' 'TFR' 'SRB' 'RNI' 'POP95_99' 'POP90_94' 'POP85_89' 'POP80_84'\n",
      " 'POP75_79' 'POP70_74' 'POP65_69' 'POP60_64' 'POP5_9' 'POP55_59'\n",
      " 'POP50_54' 'POP45_49' 'POP40_44' 'POP35_39' 'POP30_34' 'POP25_29'\n",
      " 'POP20_24' 'POP15_19' 'POP10_14' 'POP100_' 'POP0_4' 'POP' 'NMR' 'NAME'\n",
      " 'MR1_4' 'MR0_4' 'MPOP95_99' 'MPOP90_94' 'MPOP85_89' 'MPOP80_84'\n",
      " 'MPOP75_79' 'MPOP70_74' 'MPOP65_69' 'MPOP60_64' 'MPOP5_9' 'MPOP55_59'\n",
      " 'MPOP50_54' 'MPOP45_49' 'MPOP40_44' 'MPOP35_39' 'MPOP30_34' 'MPOP25_29'\n",
      " 'MPOP20_24' 'MPOP15_19' 'MPOP10_14' 'MPOP100_' 'MPOP0_4' 'MPOP' 'MMR1_4'\n",
      " 'MMR0_4' 'IMR_M' 'IMR_F' 'IMR' 'GRR' 'GR' 'FPOP95_99' 'FPOP90_94'\n",
      " 'FPOP85_89' 'FPOP80_84' 'FPOP75_79' 'FPOP70_74' 'FPOP65_69' 'FPOP60_64'\n",
      " 'FPOP5_9' 'FPOP55_59' 'FPOP50_54' 'FPOP45_49' 'FPOP40_44' 'FPOP35_39'\n",
      " 'FPOP30_34' 'FPOP25_29' 'FPOP20_24' 'FPOP15_19' 'FPOP10_14' 'FPOP100_'\n",
      " 'FPOP0_4' 'FPOP' 'FMR1_4' 'FMR0_4' 'GENC' 'FIPS' 'E0_M' 'E0_F' 'E0' 'CDR'\n",
      " 'CBR' 'ASFR45_49' 'ASFR40_44' 'ASFR35_39' 'ASFR30_34' 'ASFR25_29'\n",
      " 'ASFR20_24' 'ASFR15_19' 'AREA_KM2' 'POP_DENS']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load each of the datasets into a dataframe\n",
    "\n",
    "print(\"*********** Dataset #1 (1951 - 2020) ***********\\n\")\n",
    "df_1 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/world-population_1.csv')\n",
    "print(\"--> Columns:\", df_1.columns.values)\n",
    "#print(df_1.info())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"*********** Dataset #2 (2021 - Present) ***********\\n\")\n",
    "df_2 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/world-population_2.csv')\n",
    "print(\"--> Columns:\", df_2.columns.values)\n",
    "#print(df_2.info())\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"*********** Dataset #3 (1951 - Present) ***********\\n\")\n",
    "df_3 = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/idb5yr.all', delimiter='|', encoding='ISO-8859-1')\n",
    "print(\"--> Columns:\", df_3.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-reception",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "Printing out the information about the dataframe we are able to see that there are a\n",
    "total of 7 attributes in the first dataset, and 8 in the second.\n",
    "\n",
    "Attributes includes:\n",
    "- Description\n",
    "\n",
    "Below is a brief description of some of the key attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "widespread-porter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 7905336896\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>POP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2018</td>\n",
       "      <td>7597066210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019</td>\n",
       "      <td>7676686052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2020</td>\n",
       "      <td>7756873419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2021</td>\n",
       "      <td>7831718605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2022</td>\n",
       "      <td>7905336896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEAR         POP\n",
       "67  2018  7597066210\n",
       "68  2019  7676686052\n",
       "69  2020  7756873419\n",
       "70  2021  7831718605\n",
       "71  2022  7905336896"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make year column easier to understand\n",
    "df_3.rename(columns={'#YR':'YEAR'}, inplace=True)\n",
    "\n",
    "# Remove every column except for year & population\n",
    "for col in df_3.columns.values:\n",
    "    if col != 'YEAR' and col != 'POP':\n",
    "        df_3.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Group by year & get sum\n",
    "df = df_3.groupby(by='YEAR')\n",
    "df = df['POP'].sum()\n",
    "\n",
    "# Finally create a new dataframe with new data\n",
    "pop_sum = []\n",
    "for i in range(1951, 2023):\n",
    "    pop_sum.append(df[i])\n",
    "df_pop = pd.DataFrame({'YEAR': list(range(1951, 2023)), 'POP': pop_sum})\n",
    "\n",
    "print(\"Current:\", df_pop['POP'][71])\n",
    "df_pop.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-dancing",
   "metadata": {},
   "source": [
    "| Variable | Description | Type | Range |\n",
    "| -------- | ----------- | ---- | ----- |\n",
    "| A        | B           | C    | D     |   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-franchise",
   "metadata": {},
   "source": [
    "The numbers above match exactly with what the numbers shown on the [__IDB web tool__](https://www.census.gov/data-tools/demo/idb/#/country?COUNTRY_YEAR=2022&COUNTRY_YR_ANIM=2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-investing",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Normalizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neural-boundary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total - 2020: 7697427912\n",
      "Total - 2021: 7817937695\n"
     ]
    }
   ],
   "source": [
    "# Python\n",
    "\n",
    "total_2020 = 0\n",
    "total_2021 = 0\n",
    "for r in range(len(df_2)):\n",
    "    total_2020 += int(df_2['2020_population'][r].replace(',',''))\n",
    "    total_2021 += int(df_2['2021_last_updated'][r].replace(',',''))\n",
    "    #total += int(aye)\n",
    "    #total += df_2['2021_last_updated'][r]\n",
    "\n",
    "print(\"Total - 2020:\", total_2020)\n",
    "print(\"Total - 2021:\", total_2021)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-participation",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Data Quality\n",
    "\n",
    "Using the `missingno` package, we are able to additionally confirm that all the data is complete and there is no missing entries with the dataset. If there was missing data, we could impute the missing values by using the k-nearest neighbor. But if an instance was missing a majority of its attributes, it would be removed from the dataset.\n",
    "\n",
    "The number of unique values in the column \" \" is printed to verify that all instances\n",
    "are weighted equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "serial-antique",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4ff7da0cb934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.8/site-packages/missingno/missingno.py\u001b[0m in \u001b[0;36mmatrix\u001b[0;34m(df, filter, n, p, sort, figsize, width_ratios, color, fontsize, labels, sparkline, inline, freq, ax)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# z is the color-mask array, g is a NxNx3 matrix. Apply the z color-mask to set the RGB of each pixel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-backup",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "\n",
    "# Given as to how\n",
    "\n",
    "\n",
    "\n",
    "del df['']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-receptor",
   "metadata": {},
   "source": [
    "\n",
    "-------------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.5 Creating Training & Test Data\n",
    "Using Scikit-learn's [cross-validation modules](https://scikit-learn.org/stable/modules/cross_validation.html) we are able to split our dataset for training and testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create X data & y target dataframe's\n",
    "y = df[''].values\n",
    "# del df['']\n",
    "X = df.to_numpy()\n",
    "\n",
    "\n",
    "# Divide the data: 80% Training & 20% Testing.  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training Set\", \"\\n   - Data Shape:\",X_train.shape,\"\\n   - Target Shape:\",y_train.shape)\n",
    "print(\"\\nTesting Set\",\"\\n   - Data Shape:\",X_test.shape ,\"\\n   - Target Shape:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-istanbul",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "We perform a split within our dataset: 80% will be used for training, and 20% for testing. The 80/20 split is appropriate for\n",
    "the dataset because recall that the end goal is for users to be able to determine the probabilities of the earth's population 100 years from now.\n",
    "\n",
    "\n",
    "--------------------\n",
    "\n",
    "## 3. Modeling\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-bradford",
   "metadata": {},
   "source": [
    "\n",
    "----------------------\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2 Custom Classifier Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-flour",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "\n",
    "## 4. Deployment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-clinton",
   "metadata": {},
   "source": [
    "\n",
    "---------------------\n",
    "\n",
    "#### References\n",
    "\n",
    "Worldometer. World Population by Year. https://www.worldometers.info/world-population/world-population-by-year/ (Accessed 01-22-2022)\n",
    "\n",
    "Scikit-learn. Cross-validation. https://scikit-learn.org/stable/modules/cross_validation.html (Accessed 01-22-2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-headline",
   "metadata": {},
   "source": [
    "# Population Prediction\n",
    "\n",
    "### Luis Garduno\n",
    "\n",
    "## 1. Data Understanding\n",
    "\n",
    "Dataset: [__International Database (IDB)__](https://www.census.gov/data-tools/demo/idb/#/country?COUNTRY_YEAR=2022&COUNTRY_YR_ANIM=2022)\n",
    "\n",
    "Question Of Interest: Predict the population of earth in 2122.\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confidential-momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34237 entries, 0 to 34236\n",
      "Data columns (total 99 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   #YR        34237 non-null  int64  \n",
      " 1   TFR        26163 non-null  float64\n",
      " 2   SRB        26163 non-null  float64\n",
      " 3   RNI        26172 non-null  float64\n",
      " 4   POP95_99   26171 non-null  float64\n",
      " 5   POP90_94   26171 non-null  float64\n",
      " 6   POP85_89   26171 non-null  float64\n",
      " 7   POP80_84   26171 non-null  float64\n",
      " 8   POP75_79   26171 non-null  float64\n",
      " 9   POP70_74   26171 non-null  float64\n",
      " 10  POP65_69   26171 non-null  float64\n",
      " 11  POP60_64   26171 non-null  float64\n",
      " 12  POP5_9     26171 non-null  float64\n",
      " 13  POP55_59   26171 non-null  float64\n",
      " 14  POP50_54   26171 non-null  float64\n",
      " 15  POP45_49   26171 non-null  float64\n",
      " 16  POP40_44   26171 non-null  float64\n",
      " 17  POP35_39   26171 non-null  float64\n",
      " 18  POP30_34   26171 non-null  float64\n",
      " 19  POP25_29   26171 non-null  float64\n",
      " 20  POP20_24   26171 non-null  float64\n",
      " 21  POP15_19   26171 non-null  float64\n",
      " 22  POP10_14   26171 non-null  float64\n",
      " 23  POP100_    26171 non-null  float64\n",
      " 24  POP0_4     26171 non-null  float64\n",
      " 25  POP        34237 non-null  int64  \n",
      " 26  NMR        26172 non-null  float64\n",
      " 27  NAME       34237 non-null  object \n",
      " 28  MR1_4      26163 non-null  float64\n",
      " 29  MR0_4      26163 non-null  float64\n",
      " 30  MPOP95_99  26171 non-null  float64\n",
      " 31  MPOP90_94  26171 non-null  float64\n",
      " 32  MPOP85_89  26171 non-null  float64\n",
      " 33  MPOP80_84  26171 non-null  float64\n",
      " 34  MPOP75_79  26171 non-null  float64\n",
      " 35  MPOP70_74  26171 non-null  float64\n",
      " 36  MPOP65_69  26171 non-null  float64\n",
      " 37  MPOP60_64  26171 non-null  float64\n",
      " 38  MPOP5_9    26171 non-null  float64\n",
      " 39  MPOP55_59  26171 non-null  float64\n",
      " 40  MPOP50_54  26171 non-null  float64\n",
      " 41  MPOP45_49  26171 non-null  float64\n",
      " 42  MPOP40_44  26171 non-null  float64\n",
      " 43  MPOP35_39  26171 non-null  float64\n",
      " 44  MPOP30_34  26171 non-null  float64\n",
      " 45  MPOP25_29  26171 non-null  float64\n",
      " 46  MPOP20_24  26171 non-null  float64\n",
      " 47  MPOP15_19  26171 non-null  float64\n",
      " 48  MPOP10_14  26171 non-null  float64\n",
      " 49  MPOP100_   26171 non-null  float64\n",
      " 50  MPOP0_4    26171 non-null  float64\n",
      " 51  MPOP       26171 non-null  float64\n",
      " 52  MMR1_4     26163 non-null  float64\n",
      " 53  MMR0_4     26163 non-null  float64\n",
      " 54  IMR_M      26163 non-null  float64\n",
      " 55  IMR_F      26163 non-null  float64\n",
      " 56  IMR        26163 non-null  float64\n",
      " 57  GRR        26163 non-null  float64\n",
      " 58  GR         26172 non-null  float64\n",
      " 59  FPOP95_99  26171 non-null  float64\n",
      " 60  FPOP90_94  26171 non-null  float64\n",
      " 61  FPOP85_89  26171 non-null  float64\n",
      " 62  FPOP80_84  26171 non-null  float64\n",
      " 63  FPOP75_79  26171 non-null  float64\n",
      " 64  FPOP70_74  26171 non-null  float64\n",
      " 65  FPOP65_69  26171 non-null  float64\n",
      " 66  FPOP60_64  26171 non-null  float64\n",
      " 67  FPOP5_9    26171 non-null  float64\n",
      " 68  FPOP55_59  26171 non-null  float64\n",
      " 69  FPOP50_54  26171 non-null  float64\n",
      " 70  FPOP45_49  26171 non-null  float64\n",
      " 71  FPOP40_44  26171 non-null  float64\n",
      " 72  FPOP35_39  26171 non-null  float64\n",
      " 73  FPOP30_34  26171 non-null  float64\n",
      " 74  FPOP25_29  26171 non-null  float64\n",
      " 75  FPOP20_24  26171 non-null  float64\n",
      " 76  FPOP15_19  26171 non-null  float64\n",
      " 77  FPOP10_14  26171 non-null  float64\n",
      " 78  FPOP100_   26171 non-null  float64\n",
      " 79  FPOP0_4    26171 non-null  float64\n",
      " 80  FPOP       26171 non-null  float64\n",
      " 81  FMR1_4     26163 non-null  float64\n",
      " 82  FMR0_4     26163 non-null  float64\n",
      " 83  GENC       34086 non-null  object \n",
      " 84  FIPS       34237 non-null  object \n",
      " 85  E0_M       26163 non-null  float64\n",
      " 86  E0_F       26163 non-null  float64\n",
      " 87  E0         26163 non-null  float64\n",
      " 88  CDR        26172 non-null  float64\n",
      " 89  CBR        26172 non-null  float64\n",
      " 90  ASFR45_49  26173 non-null  float64\n",
      " 91  ASFR40_44  26173 non-null  float64\n",
      " 92  ASFR35_39  26173 non-null  float64\n",
      " 93  ASFR30_34  26173 non-null  float64\n",
      " 94  ASFR25_29  26173 non-null  float64\n",
      " 95  ASFR20_24  26173 non-null  float64\n",
      " 96  ASFR15_19  26173 non-null  float64\n",
      " 97  AREA_KM2   34237 non-null  int64  \n",
      " 98  POP_DENS   34237 non-null  float64\n",
      "dtypes: float64(93), int64(3), object(3)\n",
      "memory usage: 25.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load dataset into dataframe\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/luisegarduno/MachineLearning_Projects/master/data/idb5yr.all', delimiter='|', encoding='ISO-8859-1')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"--> Columns:\", df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as mn\n",
    "\n",
    "mn.matrix(df)\n",
    "\n",
    "# Count unique values in column 'gameId' of the dataframe\n",
    "print('Number of unique values in column \"gameId\" : ', df['gameId'].nunique())\n",
    "\n",
    "dup_df = df.replace(to_replace=-1,value=np.nan)\n",
    "\n",
    "dup_df = dup_df.duplicated()\n",
    "print('Duplicates : ', len(df[dup_df]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
