{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa1c59-8399-4d20-86f1-814fbce8ce82",
   "metadata": {},
   "source": [
    "# Character RNNs: Generating Shakespearean Text\n",
    "\n",
    "### Luis G.\n",
    "\n",
    "Dataset : [Shakespear Dataset](https://homl.info/shakespeare) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd288e1b-5825-46e4-b6e2-d569d1ce6854",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1287b585-13a9-48b8-aa36-bf009ea4405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Download Shakespeare's dataset\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "file_name = \"shakespeare.txt\"\n",
    "filepath = keras.utils.get_file(file_name, shakespeare_url)\n",
    "\n",
    "# Read/Store text file in string\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "# Print a small section of the dataset\n",
    "print(shakespeare_text[: len(shakespeare_text) // 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec78c6-2f78-4254-a6a8-276347374188",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Text/Word Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8d9cf6-1193-4d2c-8061-ed7419b569aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Characters: 39\n",
      "Dataset size: 1115394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize - encode each CHARACTER as an integer/id\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)\n",
    "\n",
    "# Number of distinct characters\n",
    "max_id = len(tokenizer.word_index)\n",
    "print(\"Distinct Characters:\", max_id)\n",
    "\n",
    "# Total number of characters\n",
    "dataset_size = tokenizer.document_count\n",
    "print(\"Dataset size:\", dataset_size)\n",
    "\n",
    "# Verify tokenizer -> ex: word - \"First\"\n",
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47480e4-dba0-4993-8471-fc6bcb0e44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the entire dataset so each char is represented by it's unique ID\n",
    "# - Subtract by 1, to get vals 0-38 vs. 1-39\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21910334-a202-4f35-ba7c-225da976be9e",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Creating Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82274f13-24b6-4df7-adf1-b2922bc94c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 06:03:24.913650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:24.916947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:24.917056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:24.917755: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 06:03:24.918534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:24.918641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:24.918732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:25.246830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:25.246988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:25.247088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 06:03:25.247168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7516 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Training set = 90%\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30236a7-9ed0-4ed5-9f65-50924e74c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "\n",
    "# target = input shifted 1 character ahead\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844697b0-9bcd-4514-bdc1-0b1d30d4cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a943a6-74ee-498d-a139-d0f9d5c7e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "batch_size = 32    \n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff22c6f-0dea-40b3-bd53-dabfdd1a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each char using one-hot vector since there's only 39 distinct characters\n",
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "\n",
    "# Add prefetching to dataset\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250d061-4079-452d-82c9-c42059b51701",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "## 2. Modeling\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Exploring Recurrent Network Architectures: GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5c05a8-871f-4c08-9ed4-c71cb8237ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 06:03:27.832102: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8/Unknown - 3s 7ms/step - loss: 3.5915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 06:03:28.268379: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31368/31368 [==============================] - 202s 6ms/step - loss: 1.6172\n",
      "Epoch 2/20\n",
      "31368/31368 [==============================] - 199s 6ms/step - loss: 1.5374\n",
      "Epoch 3/20\n",
      "31368/31368 [==============================] - 208s 7ms/step - loss: 1.5176\n",
      "Epoch 4/20\n",
      "31368/31368 [==============================] - 211s 7ms/step - loss: 1.5061\n",
      "Epoch 5/20\n",
      "31368/31368 [==============================] - 208s 7ms/step - loss: 1.4986\n",
      "Epoch 6/20\n",
      "31368/31368 [==============================] - 200s 6ms/step - loss: 1.4924\n",
      "Epoch 7/20\n",
      "31368/31368 [==============================] - 200s 6ms/step - loss: 1.4882\n",
      "Epoch 8/20\n",
      "31368/31368 [==============================] - 199s 6ms/step - loss: 1.4848\n",
      "Epoch 9/20\n",
      "31368/31368 [==============================] - 210s 7ms/step - loss: 1.4820\n",
      "Epoch 10/20\n",
      "31368/31368 [==============================] - 210s 7ms/step - loss: 1.4797\n",
      "Epoch 11/20\n",
      "31368/31368 [==============================] - 209s 7ms/step - loss: 1.4779\n",
      "Epoch 12/20\n",
      "31368/31368 [==============================] - 209s 7ms/step - loss: 1.4759\n",
      "Epoch 13/20\n",
      "31368/31368 [==============================] - 207s 7ms/step - loss: 1.4741\n",
      "Epoch 14/20\n",
      "31368/31368 [==============================] - 200s 6ms/step - loss: 1.4729\n",
      "Epoch 15/20\n",
      "31368/31368 [==============================] - 201s 6ms/step - loss: 1.4718\n",
      "Epoch 16/20\n",
      "31368/31368 [==============================] - 203s 6ms/step - loss: 1.4706\n",
      "Epoch 17/20\n",
      "31368/31368 [==============================] - 203s 6ms/step - loss: 1.4697\n",
      "Epoch 18/20\n",
      "31368/31368 [==============================] - 201s 6ms/step - loss: 1.4687\n",
      "Epoch 19/20\n",
      "31368/31368 [==============================] - 202s 6ms/step - loss: 1.4679\n",
      "Epoch 20/20\n",
      "31368/31368 [==============================] - 205s 7ms/step - loss: 1.4672\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, TimeDistributed, Dense\n",
    "\n",
    "model = Sequential([\n",
    "            GRU(128, return_sequences=True, input_shape=[None,max_id], dropout=0.2),\n",
    "            GRU(128, return_sequences=True, dropout=0.2),\n",
    "            TimeDistributed(Dense(max_id, activation=\"softmax\"))\n",
    "        ])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset,epochs=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
