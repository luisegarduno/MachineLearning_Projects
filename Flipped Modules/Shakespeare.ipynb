{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6fa1c59-8399-4d20-86f1-814fbce8ce82",
   "metadata": {},
   "source": [
    "# Character RNNs: Generating Shakespearean Text\n",
    "\n",
    "### Luis G.\n",
    "\n",
    "Dataset : [Shakespear Dataset](https://homl.info/shakespeare) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd288e1b-5825-46e4-b6e2-d569d1ce6854",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "\n",
    "## 1. Preparation\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1287b585-13a9-48b8-aa36-bf009ea4405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Download Shakespeare's dataset\n",
    "shakespeare_url = \"https://homl.info/shakespeare\"\n",
    "file_name = \"shakespeare.txt\"\n",
    "filepath = keras.utils.get_file(file_name, shakespeare_url)\n",
    "\n",
    "# Read/Store text file in string\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()\n",
    "\n",
    "# Print a small section of the dataset\n",
    "print(shakespeare_text[: len(shakespeare_text) // 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec78c6-2f78-4254-a6a8-276347374188",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Text/Word Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8d9cf6-1193-4d2c-8061-ed7419b569aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Characters: 39\n",
      "Dataset size: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize - encode each CHARACTER as an integer/id\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([shakespeare_text])\n",
    "\n",
    "# Number of distinct characters\n",
    "max_id = len(tokenizer.word_index)\n",
    "print(\"Distinct Characters:\", max_id)\n",
    "\n",
    "# Total number of characters\n",
    "dataset_size = tokenizer.document_count\n",
    "print(\"Dataset size:\", dataset_size)\n",
    "\n",
    "# Verify tokenizer -> ex: word - \"First\"\n",
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c47480e4-dba0-4993-8471-fc6bcb0e44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the entire dataset so each char is represented by it's unique ID\n",
    "# - Subtract by 1, to get vals 0-38 vs. 1-39\n",
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21910334-a202-4f35-ba7c-225da976be9e",
   "metadata": {},
   "source": [
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Creating Training & Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82274f13-24b6-4df7-adf1-b2922bc94c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-10 05:21:14.898085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:14.901547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:14.901662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:14.902616: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-10 05:21:14.903462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:14.903580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:14.903670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:15.237306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:15.237450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:15.237550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-11-10 05:21:15.237640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7476 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Training set = 90%\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d30236a7-9ed0-4ed5-9f65-50924e74c80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "\n",
    "# target = input shifted 1 character ahead\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "844697b0-9bcd-4514-bdc1-0b1d30d4cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a943a6-74ee-498d-a139-d0f9d5c7e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32    \n",
    "dataset = dataset.shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb639d9-36c5-401d-8ea0-942e9bc7a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff22c6f-0dea-40b3-bd53-dabfdd1a7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each char using one-hot vector since there's only 39 distinct characters\n",
    "dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "\n",
    "# Add prefetching to dataset \n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250d061-4079-452d-82c9-c42059b51701",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "\n",
    "## 2. Modeling\n",
    "\n",
    "### &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Exploring Recurrent Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a12ab13-277f-476f-9054-f2316975a7ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2645709473.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 17\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, TimeDistributed, Dense\n",
    "\n",
    "model = Sequencial()\n",
    "\n",
    "model.add(GRU(128, return_sequences=True, input_shape=[None,max_id], dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(TimeDistributed(Dense(max_id, activation=\"softmax\"))\n",
    "\n",
    "# model = Sequential([\n",
    "#             GRU(128, return_sequences=True, input_shape=[None,max_id], dropout=0.2, recurrent_dropout=0.2),\n",
    "#             GRU(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "#             TimeDistributed(Dense(max_id, activation=\"softmax\"))\n",
    "#         ])\n",
    "\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4704c356-08fd-45e6-ab82-01846da3d72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
